{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e7e4e9",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfac7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc50bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d2bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/ptb-xl/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0481363",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')[\"filename_lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02ab4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, meta = wfdb.rdsamp(path+Y.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb65d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels = 256):\n",
    "    mu = float(quantization_channels - 1)\n",
    "    quantize_space = np.linspace(-1, 1, quantization_channels)\n",
    "\n",
    "    quantized = np.sign(audio) * np.log(1 + mu * np.abs(audio)) / np.log(mu + 1)\n",
    "    quantized = np.digitize(quantized, quantize_space) - 1\n",
    "    quantized = np.where(arr == -1, 0, quantized)\n",
    "\n",
    "    return quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd2562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269761b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb41fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filenames, padding = 0, channels = 256, batch_size = 1, start = 0):\n",
    "    def load_audio(filename):\n",
    "        signal, meta = wfdb.rdsamp(filename)\n",
    "        return signal\n",
    "    \n",
    "    def one_hot_encode(data, channels=channels):\n",
    "        one_hot = np.zeros((data.size, channels), dtype=float)\n",
    "        one_hot[np.arange(data.size), data.ravel()] = 1\n",
    "\n",
    "        return one_hot\n",
    "    \n",
    "    def mu_law_encode(audio, quantization_channels=channels):\n",
    "        mu = float(quantization_channels - 1)\n",
    "        quantize_space = np.linspace(-1, 1, quantization_channels)\n",
    "\n",
    "        quantized = np.sign(audio) * np.log(1 + mu * np.abs(audio)) / np.log(mu + 1)\n",
    "        quantized = np.digitize(quantized, quantize_space) - 1\n",
    "        quantized = np.where(quantized == -1, 0, quantized)\n",
    "        \n",
    "        return quantized\n",
    "    \n",
    "    def _variable(data):\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.autograd.Variable(tensor.cuda())\n",
    "        else:\n",
    "            return torch.autograd.Variable(tensor)\n",
    "    \n",
    "    \n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    if start > len(filenames):\n",
    "        print(\"9awditiha\")\n",
    "        return\n",
    "    \n",
    "    i = start\n",
    "    \n",
    "    while i < start + batch_size and i < len(Y):\n",
    "        raw_audio = load_audio(path + filenames.iloc[i])\n",
    "\n",
    "        input_ = raw_audio[:,0]\n",
    "        input_ = np.pad(input_, [[padding, 0]], 'constant')\n",
    "        input_ = mu_law_encode(input_)\n",
    "        input_ = one_hot_encode(input_)\n",
    "\n",
    "        target = raw_audio[:,1]\n",
    "        target = mu_law_encode(target)\n",
    "        \n",
    "        input_batch.append(input_)\n",
    "        target_batch.append(target)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return _variable(np.array(input_batch)), _variable(np.array(target_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d5d167b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_receptive_fields(layer_size, stack_size):\n",
    "        layers = [2 ** i for i in range(0, layer_size)] * stack_size\n",
    "        num_receptive_fields = np.sum(layers)\n",
    "        \n",
    "        return int(num_receptive_fields)\n",
    "    \n",
    "def calc_output_size(x, receptive_fields):\n",
    "    output_size = int(x.size(1)) - receptive_fields\n",
    "    \n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9492d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wavenet.config as config\n",
    "from wavenet.model import WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1da02633",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = 5\n",
    "stack_size = 1\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79f61483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields = calc_receptive_fields(layer_size, stack_size);receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59d8b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet = WaveNet(layer_size = layer_size, stack_size = stack_size,\n",
    "                               in_channels = 256, res_channels = 512, lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1c32b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, target = get_data(Y, padding = receptive_fields, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c75d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54617fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.long().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57b94e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = calc_output_size(input_, receptive_fields);output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef85c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(-1, 256).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35efd201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b77f10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 65.,  66.,  69.,  ..., 127., 143.,  77.],\n",
       "        [210., 206., 201.,  ..., 233., 190.,  64.],\n",
       "        [ 57.,  59.,  64.,  ...,  33.,  30.,  28.],\n",
       "        ...,\n",
       "        [ 59.,  57.,  51.,  ...,  59.,  62.,  59.],\n",
       "        [ 44.,  44.,  45.,  ..., 204., 185.,  38.],\n",
       "        [225., 224., 223.,  ...,   9.,   9.,   9.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff1603a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(-1.)\n",
      "tensor(0.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "for i in target.view(-1):\n",
    "    if i <= 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "335313a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([30, 1031, 256])\n",
      "torch.Size([30, 1000])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target -1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mwavenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epoch, loss))\n",
      "File \u001b[1;32mC:\\root\\college\\stage intérnational\\ECG project\\code\\WaveNet\\wavenet\\model.py:57\u001b[0m, in \u001b[0;36mWaveNet.train\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mTrain 1 time\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m:param inputs: Tensor[batch, timestep, channels]\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m:param targets: Torch tensor [batch, timestep, channels]\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m:return: float loss\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(inputs) \u001b[38;5;66;03m# slow\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     61\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m#slow\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target -1 is out of bounds."
     ]
    }
   ],
   "source": [
    "num_epoch = 2\n",
    "for epoch in range(num_epoch):\n",
    "    for i in range(0,len(Y),batch_size):\n",
    "        print(i)\n",
    "        input_, target = get_data(Y, padding = receptive_fields, batch_size =batch_size, start = i)\n",
    "        print(input_.shape)\n",
    "        print(target.shape)\n",
    "        loss = wavenet.train(input_, target)\n",
    "        \n",
    "        print('[{0}/{1}] loss: {2}'.format(epoch + 1, num_epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b15f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb124e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e5c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = wavenet.generate(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3aad46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1000, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b016614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0041, 0.0038, 0.0040, 0.0038, 0.0038, 0.0036, 0.0038, 0.0037, 0.0039,\n",
       "        0.0040, 0.0037, 0.0037, 0.0040, 0.0041, 0.0040, 0.0041, 0.0040, 0.0040,\n",
       "        0.0038, 0.0037, 0.0039, 0.0037, 0.0037, 0.0038, 0.0037, 0.0039, 0.0038,\n",
       "        0.0038, 0.0042, 0.0038, 0.0037, 0.0038, 0.0039, 0.0040, 0.0038, 0.0041,\n",
       "        0.0042, 0.0038, 0.0041, 0.0038, 0.0041, 0.0037, 0.0038, 0.0041, 0.0037,\n",
       "        0.0040, 0.0038, 0.0039, 0.0038, 0.0038, 0.0041, 0.0039, 0.0039, 0.0038,\n",
       "        0.0038, 0.0040, 0.0042, 0.0041, 0.0040, 0.0038, 0.0037, 0.0036, 0.0039,\n",
       "        0.0038, 0.0041, 0.0043, 0.0041, 0.0041, 0.0037, 0.0040, 0.0042, 0.0038,\n",
       "        0.0037, 0.0040, 0.0039, 0.0039, 0.0037, 0.0038, 0.0040, 0.0040, 0.0037,\n",
       "        0.0038, 0.0036, 0.0040, 0.0038, 0.0038, 0.0042, 0.0042, 0.0037, 0.0040,\n",
       "        0.0037, 0.0040, 0.0039, 0.0041, 0.0038, 0.0040, 0.0040, 0.0040, 0.0040,\n",
       "        0.0038, 0.0039, 0.0040, 0.0037, 0.0039, 0.0040, 0.0042, 0.0041, 0.0038,\n",
       "        0.0040, 0.0038, 0.0041, 0.0041, 0.0037, 0.0039, 0.0038, 0.0037, 0.0040,\n",
       "        0.0036, 0.0041, 0.0038, 0.0039, 0.0039, 0.0041, 0.0041, 0.0039, 0.0041,\n",
       "        0.0040, 0.0038, 0.0040, 0.0038, 0.0038, 0.0043, 0.0038, 0.0038, 0.0038,\n",
       "        0.0040, 0.0037, 0.0040, 0.0039, 0.0041, 0.0039, 0.0041, 0.0040, 0.0040,\n",
       "        0.0040, 0.0040, 0.0041, 0.0039, 0.0038, 0.0040, 0.0038, 0.0040, 0.0037,\n",
       "        0.0038, 0.0038, 0.0037, 0.0042, 0.0038, 0.0038, 0.0037, 0.0038, 0.0038,\n",
       "        0.0041, 0.0039, 0.0043, 0.0039, 0.0041, 0.0039, 0.0039, 0.0038, 0.0039,\n",
       "        0.0038, 0.0040, 0.0038, 0.0040, 0.0037, 0.0039, 0.0040, 0.0039, 0.0042,\n",
       "        0.0040, 0.0038, 0.0043, 0.0038, 0.0039, 0.0041, 0.0037, 0.0041, 0.0040,\n",
       "        0.0040, 0.0038, 0.0039, 0.0039, 0.0039, 0.0037, 0.0040, 0.0038, 0.0041,\n",
       "        0.0041, 0.0041, 0.0042, 0.0039, 0.0037, 0.0038, 0.0043, 0.0038, 0.0038,\n",
       "        0.0039, 0.0037, 0.0039, 0.0039, 0.0037, 0.0039, 0.0041, 0.0040, 0.0037,\n",
       "        0.0039, 0.0037, 0.0038, 0.0041, 0.0040, 0.0039, 0.0038, 0.0037, 0.0036,\n",
       "        0.0042, 0.0037, 0.0040, 0.0039, 0.0037, 0.0037, 0.0038, 0.0037, 0.0041,\n",
       "        0.0038, 0.0041, 0.0043, 0.0040, 0.0039, 0.0040, 0.0038, 0.0039, 0.0037,\n",
       "        0.0039, 0.0036, 0.0041, 0.0036, 0.0042, 0.0038, 0.0037, 0.0039, 0.0038,\n",
       "        0.0041, 0.0040, 0.0038, 0.0038], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929d0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
